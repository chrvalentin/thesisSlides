import{_ as p}from"./slidev/VClick-CVzFjO0_.js";import{_ as d}from"./slidev/VClicks-CAwyv28Y.js";import{o as m,b as _,w as o,g as t,af as n,d as s,v as g,x as f,T as r}from"./modules/vue-mwjV2177.js";import{I as x}from"./slidev/two-cols-header-B1B15mGm.js";import{K as k,al as v}from"./index-CgJ94vqJ.js";import"./modules/shiki-Das6mPxj.js";const w="/thesisSlides/assets/swin_unet-BuXeiiC3.svg",T={__name:"slides.md__slidev_30",setup(S){const{$clicksContext:l,$frontmatter:i}=k();return l.setup(),(b,e)=>{const a=d,u=p;return m(),_(x,g(f(r(v)(r(i),29))),{left:o(c=>[s(a,null,{default:o(()=>[...e[0]||(e[0]=[t("ul",null,[t("li",null,[t("strong",null,"Encoder"),n(": Swin blocks + patch merging → progressively coarser representations")]),t("li",null,[t("strong",null,"Decoder"),n(": Swin blocks + patch expanding → reconstructs original resolution")]),t("li",null,[t("strong",null,"Skip connections"),n(" link corresponding encoder and decoder stages to preserve fine-grained information")])],-1)])]),_:1})]),right:o(c=>[s(u,{at:1},{default:o(()=>[...e[1]||(e[1]=[t("img",{src:w,class:"mx-auto",style:{width:"100%","max-width":"340px",height:"auto","object-fit":"contain"}},null,-1)])]),_:1})]),default:o(()=>[e[2]||(e[2]=t("h1",null,"Swin-UNet",-1)),e[3]||(e[3]=t("p",null,[n("Fully transformer-based "),t("strong",null,"encoder-decoder"),n(" architecture for semantic segmentation")],-1))]),_:1},16)}}};export{T as default};
